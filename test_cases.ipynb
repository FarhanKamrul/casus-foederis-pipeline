{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e5633583",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Duplicates in analysis file: 49",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 39\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;66;03m# 5.  No duplicate (Crisis_ID, Actor_ID, Alliance_ID)\u001b[39;00m\n\u001b[0;32m     38\u001b[0m dupes \u001b[38;5;241m=\u001b[39m analysis_df\u001b[38;5;241m.\u001b[39mduplicated([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCrisis_ID\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mActor_ID\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAlliance_ID\u001b[39m\u001b[38;5;124m\"\u001b[39m])\u001b[38;5;241m.\u001b[39msum()\n\u001b[1;32m---> 39\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m dupes \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDuplicates in analysis file: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdupes\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m✓ Global integrity tests passed\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     43\u001b[0m \u001b[38;5;66;03m# ══════════════════════════════════════════════════════════════════\u001b[39;00m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;66;03m# (B)  SPOT-CHECKS ON HISTORICAL CASES\u001b[39;00m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;66;03m# ══════════════════════════════════════════════════════════════════\u001b[39;00m\n",
      "\u001b[1;31mAssertionError\u001b[0m: Duplicates in analysis file: 49"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# Load files\n",
    "# ------------------------------------------------------------------\n",
    "# FULL      = Path(\"actor_level_data/ICB_ATOP_actor_level_20250702.csv\")\n",
    "ANALYSIS  = Path(\"actor_level_data/ICB_ATOP_actor_level_20250702_filtered.csv\")\n",
    "\n",
    "# full_df    = pd.read_csv(FULL)\n",
    "analysis_df = pd.read_csv(ANALYSIS)\n",
    "\n",
    "# Helper: parse yyyy-mm-dd safely\n",
    "to_dt = lambda s: pd.to_datetime(s, errors=\"coerce\")\n",
    "\n",
    "# ══════════════════════════════════════════════════════════════════\n",
    "# (A)  FILE-WIDE INTEGRITY TESTS\n",
    "# ══════════════════════════════════════════════════════════════════\n",
    "\n",
    "\n",
    "\"\"\" \n",
    "# 3.  Actor_TrigDate ≤ Actor_TermDate\n",
    "bad = analysis_df[to_dt(analysis_df[\"Actor_TrigDate\"]) >\n",
    "                  to_dt(analysis_df[\"Actor_TermDate\"])]\n",
    "assert bad.empty, \"Found actor rows with TrigDate > TermDate\" \"\"\"\n",
    "\n",
    "# 4.  Actor dates lie inside treaty window when Actor_Is_Member == 1\n",
    "mask = analysis_df[\"Actor_Is_Member\"] == 1\n",
    "bad = analysis_df[mask & (\n",
    "        (to_dt(analysis_df[\"Actor_TermDate\"]) <\n",
    "         to_dt(analysis_df[\"Actor_Member_Start\"])) |\n",
    "        (to_dt(analysis_df[\"Actor_TrigDate\"])  >\n",
    "         to_dt(analysis_df[\"Actor_Member_End\"]))\n",
    ")]\n",
    "assert bad.empty, \"Actor_Is_Member rows violate membership window\"\n",
    "\n",
    "# 5.  No duplicate (Crisis_ID, Actor_ID, Alliance_ID)\n",
    "dupes = analysis_df.duplicated([\"Crisis_ID\",\"Actor_ID\",\"Alliance_ID\"]).sum()\n",
    "assert dupes == 0, f\"Duplicates in analysis file: {dupes}\"\n",
    "\n",
    "print(\"✓ Global integrity tests passed\")\n",
    "\n",
    "# ══════════════════════════════════════════════════════════════════\n",
    "# (B)  SPOT-CHECKS ON HISTORICAL CASES\n",
    "# ══════════════════════════════════════════════════════════════════\n",
    "\n",
    "def has_pair(df, crisis, actor, alliance, expect):\n",
    "    \"\"\"Return True if dataset contains expected match\"\"\"\n",
    "    row = df[(df.Crisis_ID==crisis) &\n",
    "             (df.Actor_ID==actor) &\n",
    "             (df.Alliance_ID==alliance)]\n",
    "    return (not row.empty) and (row.iloc[0][\"Both_Conditions\"]==expect)\n",
    "\n",
    "# 6.  1956 Hungarian Uprising × NATO (actor=Hungary 310)  → expect 0\n",
    "assert has_pair(full_df, 155, 310, 3180, 0), \\\n",
    "    \"Hungary-NATO 1956 incorrectly marked true\"\n",
    "\n",
    "# 7.  1956 Hungarian Uprising × Warsaw Pact (actor=Hungary) → expect 1\n",
    "assert has_pair(analysis_df, 155, 310, 3185, 1), \\\n",
    "    \"Hungary-WarsawPact 1956 missing or false\"\n",
    "\n",
    "# 8.  1938 Munich Crisis × Franco-Czech Treaty (actor=Czechoslovakia 315) → 1\n",
    "assert has_pair(analysis_df, 64, 315, 2120, 1), \\\n",
    "    \"Franco-Czech Treaty 1938 not flagged true\"\n",
    "\n",
    "# 9.  2003 Iraq War × NATO (actor=USA 2) → expect 1\n",
    "assert has_pair(analysis_df, 442, 2, 3180, 1), \\\n",
    "    \"USA-NATO 2003 Iraq War missing/false\"\n",
    "\n",
    "print(\"✓ All spot-checks passed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "392877e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "⚠️  Duplicate triplets found: 94 rows across 45 unique keys\n",
      "\n",
      "Copies per (Crisis, Actor, Alliance):\n",
      " Crisis_ID  Actor_ID  Alliance_ID  Copies\n",
      "        80       360         2085       3\n",
      "        80       360         2215       3\n",
      "        80       360         2315       3\n",
      "        80       360         2330       3\n",
      "        21       315         2050       2\n",
      "       242       770         3222       2\n",
      "       216       750         3225       2\n",
      "       232       651         3015       2\n",
      "       232       651         3205       2\n",
      "       232       651         3350       2\n",
      "\n",
      "✓ All duplicate rows written to actor_level_data\\duplicate_triplets.csv\n"
     ]
    }
   ],
   "source": [
    "# ── Inspect duplicate (Crisis_ID, Actor_ID, Alliance_ID) rows ──────────────\n",
    "key = [\"Crisis_ID\", \"Actor_ID\", \"Alliance_ID\"]\n",
    "\n",
    "dup_mask = analysis_df.duplicated(key, keep=False)      # flag every copy\n",
    "dupes_df = analysis_df[dup_mask].sort_values(key)       # 49 rows in your case\n",
    "\n",
    "print(f\"\\n⚠️  Duplicate triplets found: {dupes_df.shape[0]} rows \"\n",
    "      f\"across {dupes_df[key].drop_duplicates().shape[0]} unique keys\\n\")\n",
    "\n",
    "# show how many copies per key\n",
    "count_tbl = (dupes_df.groupby(key)\n",
    "                       .size()\n",
    "                       .reset_index(name=\"Copies\")\n",
    "                       .sort_values(\"Copies\", ascending=False))\n",
    "print(\"Copies per (Crisis, Actor, Alliance):\")\n",
    "print(count_tbl.head(10).to_string(index=False))        # top 10 offenders\n",
    "\n",
    "# full details for spreadsheet review\n",
    "dup_file = Path(\"actor_level_data/duplicate_triplets.csv\")\n",
    "dupes_df.to_csv(dup_file, index=False)\n",
    "print(f\"\\n✓ All duplicate rows written to {dup_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6490f554",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Inspecting crises: [83, 232, 80]\n",
      "\n",
      "======================================================================\n",
      "CRISIS 83: BALKAN INVASIONS\n",
      "Duplicate rows: 18\n",
      "\n",
      "— Actor 200, Alliance 1400 appears 2×; varying columns: ['Actor_TrigDate', 'Actor_TermDate']\n",
      "Actor_TrigDate Actor_TermDate Actor_TrigDate Actor_TermDate\n",
      "    1940-10-28     1940-11-22     1940-10-28     1940-11-22\n",
      "    1941-04-06     1941-06-01     1941-04-06     1941-06-01\n",
      "\n",
      "— Actor 200, Alliance 2270 appears 2×; varying columns: ['Actor_TrigDate', 'Actor_TermDate']\n",
      "Actor_TrigDate Actor_TermDate Actor_TrigDate Actor_TermDate\n",
      "    1940-10-28     1940-11-22     1940-10-28     1940-11-22\n",
      "    1941-04-06     1941-06-01     1941-04-06     1941-06-01\n",
      "\n",
      "— Actor 200, Alliance 2385 appears 2×; varying columns: ['Actor_TrigDate', 'Actor_TermDate']\n",
      "Actor_TrigDate Actor_TermDate Actor_TrigDate Actor_TermDate\n",
      "    1940-10-28     1940-11-22     1940-10-28     1940-11-22\n",
      "    1941-04-06     1941-06-01     1941-04-06     1941-06-01\n",
      "\n",
      "— Actor 200, Alliance 2490 appears 2×; varying columns: ['Actor_TrigDate', 'Actor_TermDate']\n",
      "Actor_TrigDate Actor_TermDate Actor_TrigDate Actor_TermDate\n",
      "    1940-10-28     1940-11-22     1940-10-28     1940-11-22\n",
      "    1941-04-06     1941-06-01     1941-04-06     1941-06-01\n",
      "\n",
      "— Actor 345, Alliance 2250 appears 2×; varying columns: ['Actor_TrigDate', 'Actor_TermDate']\n",
      "Actor_TrigDate Actor_TermDate Actor_TrigDate Actor_TermDate\n",
      "    1940-10-28     1940-11-21     1940-10-28     1940-11-21\n",
      "    1941-03-04     1941-04-17     1941-03-04     1941-04-17\n",
      "\n",
      "— Actor 345, Alliance 2320 appears 2×; varying columns: ['Actor_TrigDate', 'Actor_TermDate']\n",
      "Actor_TrigDate Actor_TermDate Actor_TrigDate Actor_TermDate\n",
      "    1940-10-28     1940-11-21     1940-10-28     1940-11-21\n",
      "    1941-03-04     1941-04-17     1941-03-04     1941-04-17\n",
      "\n",
      "— Actor 345, Alliance 2405 appears 2×; varying columns: ['Actor_TrigDate', 'Actor_TermDate']\n",
      "Actor_TrigDate Actor_TermDate Actor_TrigDate Actor_TermDate\n",
      "    1940-10-28     1940-11-21     1940-10-28     1940-11-21\n",
      "    1941-03-04     1941-04-17     1941-03-04     1941-04-17\n",
      "\n",
      "— Actor 350, Alliance 2215 appears 2×; varying columns: ['Actor_TrigDate', 'Actor_TermDate']\n",
      "Actor_TrigDate Actor_TermDate Actor_TrigDate Actor_TermDate\n",
      "    1940-10-28     1940-11-21     1940-10-28     1940-11-21\n",
      "    1941-04-06     1941-04-23     1941-04-06     1941-04-23\n",
      "\n",
      "— Actor 350, Alliance 2250 appears 2×; varying columns: ['Actor_TrigDate', 'Actor_TermDate']\n",
      "Actor_TrigDate Actor_TermDate Actor_TrigDate Actor_TermDate\n",
      "    1940-10-28     1940-11-21     1940-10-28     1940-11-21\n",
      "    1941-04-06     1941-04-23     1941-04-06     1941-04-23\n",
      "\n",
      "======================================================================\n",
      "CRISIS 232: WAR OF ATTRITION\n",
      "Duplicate rows: 14\n",
      "\n",
      "— Actor 651, Alliance 3015 appears 2×; varying columns: ['Actor_TrigDate', 'Actor_TermDate']\n",
      "Actor_TrigDate Actor_TermDate Actor_TrigDate Actor_TermDate\n",
      "    1969-07-20     1969-07-28     1969-07-20     1969-07-28\n",
      "    1970-01-07     1970-08-07     1970-01-07     1970-08-07\n",
      "\n",
      "— Actor 651, Alliance 3205 appears 2×; varying columns: ['Actor_TrigDate', 'Actor_TermDate']\n",
      "Actor_TrigDate Actor_TermDate Actor_TrigDate Actor_TermDate\n",
      "    1969-07-20     1969-07-28     1969-07-20     1969-07-28\n",
      "    1970-01-07     1970-08-07     1970-01-07     1970-08-07\n",
      "\n",
      "— Actor 651, Alliance 3350 appears 2×; varying columns: ['Actor_TrigDate', 'Actor_TermDate']\n",
      "Actor_TrigDate Actor_TermDate Actor_TrigDate Actor_TermDate\n",
      "    1969-07-20     1969-07-28     1969-07-20     1969-07-28\n",
      "    1970-01-07     1970-08-07     1970-01-07     1970-08-07\n",
      "\n",
      "— Actor 651, Alliance 3570 appears 2×; varying columns: ['Actor_TrigDate', 'Actor_TermDate']\n",
      "Actor_TrigDate Actor_TermDate Actor_TrigDate Actor_TermDate\n",
      "    1969-07-20     1969-07-28     1969-07-20     1969-07-28\n",
      "    1970-01-07     1970-08-07     1970-01-07     1970-08-07\n",
      "\n",
      "— Actor 666, Alliance 3367 appears 2×; varying columns: ['Actor_TrigDate', 'Actor_TermDate']\n",
      "Actor_TrigDate Actor_TermDate Actor_TrigDate Actor_TermDate\n",
      "    1969-03-08     1969-07-28     1969-03-08     1969-07-28\n",
      "    1970-04-19     1970-08-07     1970-04-19     1970-08-07\n",
      "\n",
      "— Actor 666, Alliance 3458 appears 2×; varying columns: ['Actor_TrigDate', 'Actor_TermDate']\n",
      "Actor_TrigDate Actor_TermDate Actor_TrigDate Actor_TermDate\n",
      "    1969-03-08     1969-07-28     1969-03-08     1969-07-28\n",
      "    1970-04-19     1970-08-07     1970-04-19     1970-08-07\n",
      "\n",
      "— Actor 666, Alliance 3537 appears 2×; varying columns: ['Actor_TrigDate', 'Actor_TermDate']\n",
      "Actor_TrigDate Actor_TermDate Actor_TrigDate Actor_TermDate\n",
      "    1969-03-08     1969-07-28     1969-03-08     1969-07-28\n",
      "    1970-04-19     1970-08-07     1970-04-19     1970-08-07\n",
      "\n",
      "======================================================================\n",
      "CRISIS 80: ROMANIAN TERRITORY\n",
      "Duplicate rows: 12\n",
      "\n",
      "— Actor 360, Alliance 2085 appears 3×; varying columns: ['Actor_TrigDate', 'Actor_TermDate']\n",
      "Actor_TrigDate Actor_TermDate Actor_TrigDate Actor_TermDate\n",
      "    1940-06-26     1940-07-02     1940-06-26     1940-07-02\n",
      "    1940-07-01     1940-08-30     1940-07-01     1940-08-30\n",
      "    1940-07-01     1940-09-07     1940-07-01     1940-09-07\n",
      "\n",
      "— Actor 360, Alliance 2215 appears 3×; varying columns: ['Actor_TrigDate', 'Actor_TermDate']\n",
      "Actor_TrigDate Actor_TermDate Actor_TrigDate Actor_TermDate\n",
      "    1940-06-26     1940-07-02     1940-06-26     1940-07-02\n",
      "    1940-07-01     1940-08-30     1940-07-01     1940-08-30\n",
      "    1940-07-01     1940-09-07     1940-07-01     1940-09-07\n",
      "\n",
      "— Actor 360, Alliance 2315 appears 3×; varying columns: ['Actor_TrigDate', 'Actor_TermDate']\n",
      "Actor_TrigDate Actor_TermDate Actor_TrigDate Actor_TermDate\n",
      "    1940-06-26     1940-07-02     1940-06-26     1940-07-02\n",
      "    1940-07-01     1940-08-30     1940-07-01     1940-08-30\n",
      "    1940-07-01     1940-09-07     1940-07-01     1940-09-07\n",
      "\n",
      "— Actor 360, Alliance 2330 appears 3×; varying columns: ['Actor_TrigDate', 'Actor_TermDate']\n",
      "Actor_TrigDate Actor_TermDate Actor_TrigDate Actor_TermDate\n",
      "    1940-06-26     1940-07-02     1940-06-26     1940-07-02\n",
      "    1940-07-01     1940-08-30     1940-07-01     1940-08-30\n",
      "    1940-07-01     1940-09-07     1940-07-01     1940-09-07\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# Already have `analysis_df` and the duplicate mask `dup_mask`\n",
    "dup_df = analysis_df[dup_mask].copy()\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# choose crises to inspect ─ default = first 3 crises with dups\n",
    "# ------------------------------------------------------------------\n",
    "crises_to_check = (dup_df[\"Crisis_ID\"]\n",
    "                   .value_counts()\n",
    "                   .head(3)               # change .head(…) or set manually\n",
    "                   .index.tolist())\n",
    "print(f\"\\nInspecting crises: {crises_to_check}\")\n",
    "\n",
    "for cid in crises_to_check:\n",
    "    slice_df = dup_df[dup_df[\"Crisis_ID\"] == cid].sort_values(\n",
    "                   [\"Actor_ID\", \"Alliance_ID\"])\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(f\"CRISIS {cid}: {slice_df.iloc[0]['Crisis_Name']}\")\n",
    "    print(f\"Duplicate rows: {len(slice_df)}\")\n",
    "\n",
    "    # group by (Actor, Alliance) to spot field-level differences\n",
    "    for (actor, aid), group in slice_df.groupby([\"Actor_ID\",\"Alliance_ID\"]):\n",
    "        if len(group) > 1:\n",
    "            # find columns that vary within the group\n",
    "            var_cols = [col for col in group.columns\n",
    "                        if len(group[col].drop_duplicates()) > 1]\n",
    "            print(f\"\\n— Actor {actor}, Alliance {aid} appears {len(group)}×; \"\n",
    "                  f\"varying columns: {var_cols}\")\n",
    "            print(group[var_cols + [\"Actor_TrigDate\",\"Actor_TermDate\"]]\n",
    "                  .to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c08e6aad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ updated actor_level_data\\ICB_ATOP_actor_level_20250702.csv with Crisis_Phase\n",
      "✓ regenerated actor_level_data\\ICB_ATOP_actor_level_20250702_filtered.csv (rows kept: 5,102)\n"
     ]
    }
   ],
   "source": [
    "# ── Add Crisis_Phase to actor-level datasets ──────────────────────\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "FULL_CSV = Path(\"actor_level_data/ICB_ATOP_actor_level_20250702.csv\")\n",
    "FILT_CSV = Path(\"actor_level_data/ICB_ATOP_actor_level_20250702_filtered.csv\")\n",
    "\n",
    "def add_crisis_phase(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    # Parse dates so phases are ordered chronologically\n",
    "    trig = pd.to_datetime(df[\"Actor_TrigDate\"],  errors=\"coerce\")\n",
    "    term = pd.to_datetime(df[\"Actor_TermDate\"],  errors=\"coerce\")\n",
    "\n",
    "    # Order rows and assign phase numbers per Crisis–Actor pair\n",
    "    df = (df.assign(_TrigDt=trig, _TermDt=term)\n",
    "            .sort_values([\"Crisis_ID\", \"Actor_ID\", \"_TrigDt\", \"_TermDt\"])\n",
    "            .assign(Crisis_Phase=lambda x:\n",
    "                    x.groupby([\"Crisis_ID\", \"Actor_ID\"]).cumcount() + 1)\n",
    "            .drop(columns=[\"_TrigDt\", \"_TermDt\"]))\n",
    "    return df\n",
    "\n",
    "# 1) Full actor-level file\n",
    "actor_full = pd.read_csv(FULL_CSV)\n",
    "actor_full = add_crisis_phase(actor_full)\n",
    "actor_full.to_csv(FULL_CSV, index=False)\n",
    "print(f\"✓ updated {FULL_CSV} with Crisis_Phase\")\n",
    "\n",
    "# 2) Filtered analysis subset (Both_Conditions == 1)\n",
    "actor_filt = actor_full[actor_full[\"Both_Conditions\"] == 1].copy()\n",
    "actor_filt.to_csv(FILT_CSV, index=False)\n",
    "print(f\"✓ regenerated {FILT_CSV} (rows kept: {len(actor_filt):,})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6dde2f73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "File: ICB_ATOP_actor_level_20250702.csv\n",
      "  Duplicate rows: 0\n",
      "  Affected unique keys: 0\n",
      "  ✓ No duplicates under the new key\n",
      "\n",
      "File: ICB_ATOP_actor_level_20250702_filtered.csv\n",
      "  Duplicate rows: 0\n",
      "  Affected unique keys: 0\n",
      "  ✓ No duplicates under the new key\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "FULL = Path(\"actor_level_data/ICB_ATOP_actor_level_20250702.csv\")\n",
    "FILT = Path(\"actor_level_data/ICB_ATOP_actor_level_20250702_filtered.csv\")\n",
    "\n",
    "def duplicate_report(path: Path) -> None:\n",
    "    df = pd.read_csv(path)\n",
    "    key = [\"Crisis_ID\", \"Actor_ID\", \"Alliance_ID\", \"Crisis_Phase\"]\n",
    "\n",
    "    dup_total = df.duplicated(key, keep=False).sum()\n",
    "    uniq_keys = df[df.duplicated(key, keep=False)][key].drop_duplicates().shape[0]\n",
    "\n",
    "    print(f\"\\nFile: {path.name}\")\n",
    "    print(f\"  Duplicate rows: {dup_total}\")\n",
    "    print(f\"  Affected unique keys: {uniq_keys}\")\n",
    "\n",
    "    if dup_total:\n",
    "        # show first few offending keys\n",
    "        bad = (df[df.duplicated(key, keep=False)]\n",
    "               .groupby(key).size()\n",
    "               .reset_index(name=\"Copies\")\n",
    "               .sort_values(\"Copies\", ascending=False)\n",
    "               .head(10))\n",
    "        print(\"\\n  Top duplicate keys (showing up to 10):\")\n",
    "        print(bad.to_string(index=False))\n",
    "    else:\n",
    "        print(\"  ✓ No duplicates under the new key\")\n",
    "\n",
    "duplicate_report(FULL)\n",
    "duplicate_report(FILT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a75e660b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "⚠️  5 rows have Actor_TrigDate later than Actor_TermDate\n",
      "\n",
      " Crisis_ID      Crisis_Name  Actor_ID                      Actor_Name Actor_TrigDate Actor_TermDate  Actor_Location  Alliance_ID Alliance_Start Alliance_End                      Alliance_Type Actor_Member_Start Actor_Member_End  Alliance_Active  Actor_Is_Member  Both_Conditions    Crisis_Location\n",
      "       185      BERLIN WALL       265 German Democratic Republic(265)     1961-08-31     1961-08-13              32         3285     1955-05-14   1991-07-01 Defense;NonAggression;Consultation         1955-05-14       1990-10-03                1                1                1 Central Europe(32)\n",
      "       475 KOREAN LAND MINE       732                South Korea(732)     2015-08-31     2015-08-25              11         3240     1953-10-01   2030-12-31 Defense;NonAggression;Consultation         1953-10-01       2030-12-31                1                1                1      East Asia(11)\n",
      "       475 KOREAN LAND MINE       732                South Korea(732)     2015-08-31     2015-08-25              11         3755     1976-02-24   2030-12-31                      NonAggression         2004-11-27       2030-12-31                1                1                1      East Asia(11)\n",
      "       475 KOREAN LAND MINE       732                South Korea(732)     2015-08-31     2015-08-25              11         4125     1991-12-13   2030-12-31                      NonAggression         1991-12-13       2030-12-31                1                1                1      East Asia(11)\n",
      "       475 KOREAN LAND MINE       732                South Korea(732)     2015-08-31     2015-08-25              11         4365     1992-11-19   2030-12-31                      NonAggression         1992-11-19       2030-12-31                1                1                1      East Asia(11)\n",
      "\n",
      "✓ Detailed list written to actor_level_data\\inconsistent_actor_dates.csv\n"
     ]
    }
   ],
   "source": [
    "# ── Inspect rows where Actor_TrigDate > Actor_TermDate ──────────\n",
    "bad_mask = to_dt(analysis_df[\"Actor_TrigDate\"]) > to_dt(analysis_df[\"Actor_TermDate\"])\n",
    "bad = analysis_df[bad_mask].copy()\n",
    "\n",
    "print(f\"\\n⚠️  {len(bad)} rows have Actor_TrigDate later than Actor_TermDate\\n\")\n",
    "if not bad.empty:\n",
    "    show_cols = list(bad.columns)      # ← include ALL columns\n",
    "    with pd.option_context(\"display.max_columns\", None,\n",
    "                           \"display.width\", 200):\n",
    "        print(bad[show_cols].to_string(index=False))\n",
    "\n",
    "    # save full details for spreadsheet review\n",
    "    bad_file = Path(\"actor_level_data/inconsistent_actor_dates.csv\")\n",
    "    bad.to_csv(bad_file, index=False)\n",
    "    print(f\"\\n✓ Detailed list written to {bad_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2b63e4a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ updated ICB_ATOP_actor_level_20250702.csv  (rows: 892,359)\n",
      "✓ regenerated actor_level_data\\ICB_ATOP_actor_level_20250702_filtered.csv\n"
     ]
    }
   ],
   "source": [
    "# ── Add \"Alliance_Members\" to actor-level datasets ─────────────────────────\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# --------------------------------------------------------------------------\n",
    "# 1. paths\n",
    "# --------------------------------------------------------------------------\n",
    "FULL_CSV = Path(\"actor_level_data/ICB_ATOP_actor_level_20250702.csv\")\n",
    "FILT_CSV = Path(\"actor_level_data/ICB_ATOP_actor_level_20250702_filtered.csv\")\n",
    "ATOP_MBR = Path(r\"atop_5.1__.csv_\\ATOP 5.1 (.csv)\\atop5_1m.csv\")\n",
    "COW_CSV  = Path(\"COW-country-codes.csv\")\n",
    "\n",
    "# --------------------------------------------------------------------------\n",
    "# 2. country-code → name mapping  (incl. three extra entities)\n",
    "# --------------------------------------------------------------------------\n",
    "cow = pd.read_csv(COW_CSV)[[\"CCode\", \"StateNme\"]]\n",
    "code2name = dict(zip(cow.CCode, cow.StateNme))\n",
    "code2name.update({219: \"Vichy France\", 671: \"Hejaz\", 672: \"Najd\"})\n",
    "\n",
    "# --------------------------------------------------------------------------\n",
    "# 3. alliance-id → formatted member list  (Name(code);Name(code)…)\n",
    "# --------------------------------------------------------------------------\n",
    "roster = pd.read_csv(ATOP_MBR, usecols=[\"atopid\", \"member\"])\n",
    "roster[\"member\"] = roster[\"member\"].astype(int)\n",
    "\n",
    "def fmt(lst):\n",
    "    return \";\".join(f\"{code2name.get(c, 'Unknown')}({c})\" for c in sorted(set(lst)))\n",
    "\n",
    "alli2members = (roster.groupby(\"atopid\")[\"member\"]\n",
    "                        .apply(fmt)\n",
    "                        .to_dict())\n",
    "\n",
    "# --------------------------------------------------------------------------\n",
    "# 4. helper to append the column and resave\n",
    "# --------------------------------------------------------------------------\n",
    "def add_members_column(path: Path):\n",
    "    df = pd.read_csv(path)\n",
    "    df[\"Alliance_Members\"] = df[\"Alliance_ID\"].map(alli2members).fillna(\"\")\n",
    "    df.to_csv(path, index=False)\n",
    "    print(f\"✓ updated {path.name}  (rows: {len(df):,})\")\n",
    "\n",
    "# full file\n",
    "add_members_column(FULL_CSV)\n",
    "\n",
    "# regenerate filtered file from the updated full (Both_Conditions == 1)\n",
    "full_df = pd.read_csv(FULL_CSV)\n",
    "full_df[full_df[\"Both_Conditions\"] == 1]\\\n",
    "       .to_csv(FILT_CSV, index=False)\n",
    "print(f\"✓ regenerated {FILT_CSV}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "44a189e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample (first 10 crises):\n",
      " Crisis_ID  Avg_Phases\n",
      "         1       789.0\n",
      "         2       789.0\n",
      "         3       789.0\n",
      "         4       789.0\n",
      "         5       789.0\n",
      "         6      1052.0\n",
      "         7       789.0\n",
      "         8       789.0\n",
      "         9       789.0\n",
      "        10       789.0\n",
      "\n",
      "Overall average number of phases per crisis: 803.177\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "FULL = Path(\"actor_level_data/ICB_ATOP_actor_level_20250702.csv\")\n",
    "df   = pd.read_csv(FULL)\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 1.  highest phase reached by each actor in each crisis\n",
    "# ------------------------------------------------------------------\n",
    "phase_by_actor = (df.groupby([\"Crisis_ID\", \"Actor_ID\"])[\"Crisis_Phase\"]\n",
    "                    .max()\n",
    "                    .reset_index(name=\"Max_Phase\"))\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 2.  average phases per crisis  (mean of actor-level maxima)\n",
    "# ------------------------------------------------------------------\n",
    "avg_phase_per_crisis = (phase_by_actor.groupby(\"Crisis_ID\")[\"Max_Phase\"]\n",
    "                          .mean()\n",
    "                          .reset_index(name=\"Avg_Phases\"))\n",
    "\n",
    "print(\"\\nSample (first 10 crises):\")\n",
    "print(avg_phase_per_crisis.head(10).to_string(index=False))\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 3.  overall mean across crises\n",
    "# ------------------------------------------------------------------\n",
    "overall_mean = avg_phase_per_crisis[\"Avg_Phases\"].mean()\n",
    "print(f\"\\nOverall average number of phases per crisis: {overall_mean:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cac1b75d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Crisis_Phase rebuilt; duplicates with phase key = 0\n",
      "✓ overwrote ICB_ATOP_actor_level_20250702.csv (rows: 892,359)\n",
      "✓ regenerated ICB_ATOP_actor_level_20250702_filtered.csv (rows: 5,102)\n",
      "Overall average phases per crisis now: 1.018\n"
     ]
    }
   ],
   "source": [
    "# ── Rebuild Crisis_Phase using unique actor windows ───────────────\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "FULL = Path(\"actor_level_data/ICB_ATOP_actor_level_20250702.csv\")\n",
    "FILT = Path(\"actor_level_data/ICB_ATOP_actor_level_20250702_filtered.csv\")\n",
    "\n",
    "# 1. load full actor-level data\n",
    "df = pd.read_csv(FULL)\n",
    "\n",
    "# 2. parse dates once for reliable ordering\n",
    "df[\"Trig_dt\"] = pd.to_datetime(df[\"Actor_TrigDate\"], errors=\"coerce\")\n",
    "df[\"Term_dt\"] = pd.to_datetime(df[\"Actor_TermDate\"], errors=\"coerce\")\n",
    "\n",
    "# 3. build the unique-window table\n",
    "windows = (df[[\"Crisis_ID\",\"Actor_ID\",\"Trig_dt\",\"Term_dt\"]]\n",
    "           .drop_duplicates()\n",
    "           .sort_values([\"Crisis_ID\",\"Actor_ID\",\"Trig_dt\",\"Term_dt\"])\n",
    "           .assign(Crisis_Phase=lambda x:\n",
    "                   x.groupby([\"Crisis_ID\",\"Actor_ID\"]).cumcount() + 1))\n",
    "\n",
    "# 4. merge phase back to every alliance row\n",
    "df = (df.drop(columns=\"Crisis_Phase\", errors=\"ignore\")      # if old column exists\n",
    "        .merge(windows, on=[\"Crisis_ID\",\"Actor_ID\",\"Trig_dt\",\"Term_dt\"],\n",
    "               how=\"left\", validate=\"many_to_one\"))\n",
    "\n",
    "# 5. clean up helper columns\n",
    "df = df.drop(columns=[\"Trig_dt\",\"Term_dt\"])\n",
    "\n",
    "# 6. sanity check: new key must be unique\n",
    "dupes = df.duplicated([\"Crisis_ID\",\"Actor_ID\",\"Alliance_ID\",\"Crisis_Phase\"]).sum()\n",
    "assert dupes == 0, f\"Still {dupes} duplicates - inspect manually\"\n",
    "print(\"✓ Crisis_Phase rebuilt; duplicates with phase key = 0\")\n",
    "\n",
    "# 7. overwrite full file\n",
    "df.to_csv(FULL, index=False)\n",
    "print(f\"✓ overwrote {FULL.name} (rows: {len(df):,})\")\n",
    "\n",
    "# 8. regenerate filtered subset (Both_Conditions == 1)\n",
    "df_filt = df[df[\"Both_Conditions\"] == 1].copy()\n",
    "df_filt.to_csv(FILT, index=False)\n",
    "print(f\"✓ regenerated {FILT.name} (rows: {len(df_filt):,})\")\n",
    "\n",
    "# 9. quick stats\n",
    "avg_phase = (df.groupby([\"Crisis_ID\",\"Actor_ID\"])[\"Crisis_Phase\"]\n",
    "               .max()\n",
    "               .groupby(\"Crisis_ID\")\n",
    "               .mean()\n",
    "               .mean())\n",
    "print(f\"Overall average phases per crisis now: {avg_phase:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11572c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── 10. also save JSON versions ───────────────────────────────────\n",
    "for path, data in [(FULL, df), (FILT, df_filt)]:\n",
    "    js_path = path.with_suffix(\".json\")\n",
    "\n",
    "    # stringify date columns for JSON compatibility\n",
    "    date_cols = [\"Crisis_Start\", \"Crisis_End\",\n",
    "                 \"Alliance_Start\", \"Alliance_End\",\n",
    "                 \"Actor_TrigDate\", \"Actor_TermDate\"]\n",
    "    data_out = data.copy()\n",
    "    for col in date_cols:\n",
    "        if col in data_out.columns:\n",
    "            data_out[col] = data_out[col].astype(str)\n",
    "\n",
    "    data_out.to_json(js_path, orient=\"records\", indent=2)\n",
    "    print(f\"✓ wrote {js_path.name} (records: {len(data_out):,})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "05dcfdde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ wrote ICB_ATOP_actor_level_20250702.json (records: 892,359)\n",
      "✓ wrote ICB_ATOP_actor_level_20250702_filtered.json (records: 5,102)\n"
     ]
    }
   ],
   "source": [
    "# ── 10. also save JSON versions ───────────────────────────────────\n",
    "for path, data in [(FULL, df), (FILT, df_filt)]:\n",
    "    js_path = path.with_suffix(\".json\")\n",
    "\n",
    "    # stringify date columns for JSON compatibility\n",
    "    date_cols = [\"Crisis_Start\", \"Crisis_End\",\n",
    "                 \"Alliance_Start\", \"Alliance_End\",\n",
    "                 \"Actor_TrigDate\", \"Actor_TermDate\"]\n",
    "    data_out = data.copy()\n",
    "    for col in date_cols:\n",
    "        if col in data_out.columns:\n",
    "            data_out[col] = data_out[col].astype(str)\n",
    "\n",
    "    data_out.to_json(js_path, orient=\"records\", indent=2)\n",
    "    print(f\"✓ wrote {js_path.name} (records: {len(data_out):,})\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
